log_level: DEBUG

feature_flags:
  all: true

inference:
  address: "http://localhost:2114/api/v1/infer"
  timeout: 10
  token: "98eb568c-dea5-4347-a3a5-583478983bb9"
  # Define custom models/vectorizer, which get handled directly in Qdrant. These do not require an `address` to be configured.
  custom_models:
    # Prefix to identify custom models. For example "custom" to reference models like "custom/bm25".
    model_prefix: "custom"
    # BM25 vectorizer configs.
    bm25:
        # Specify the name of the vectorizer to be used with this configuration. It must be unique.
      - model_name: "bm25"
        # Hyperparameters for bm25 itself.
        k: 1.2
        b: 0.75
        avg_len: 256.0
        # The tokenizer to use. Can be one of prefix, whitespace, word, multilingual. Default is word.
        tokenizer: word
        # Configurations for the tokenizer.
        tokenizer_config:
          # Whether to convert all tokens to lowercase.
          lowercase: false
          # Use predefined set of stopwords for english.
          stopwords_filter: 
            languages: 
              - english
            custom:
              - hello
          # Enables stemming using the English ruleset and the Snowball stemming algorithm.
          stemmer:
            type: snowball
            language: english
          # Specify the minimum and maximum token lengths used by certain tokenizers.
          min_token_len: null
          max_token_len: null

service:
  host: 127.0.0.1
  http_port: 6333
  # Uncomment to enable gRPC:
  #grpc_port: 6334
  #api_key: your_secret_api_key_here

cluster:
  resharding_enabled: true

storage:
  performance:
    # Number of parallel threads used for search operations. If 0 - auto selection.
    max_search_threads: 4

  optimizers:
    # Minimum interval between forced flushes.
    flush_interval_sec: 5

    # Do not create too much segments in dev
    default_segment_number: 2

  handle_collection_load_errors: true
